\documentclass[10pt,draftclsnofoot,onecolumn]{IEEEtran}
\usepackage{glossaries}
\usepackage{url}

% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex


% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

\makeglossaries

\begin{document}
\title{Semantic Diff via C\# Compiler Platform}

\author{Shawn Fontaine, Cody Hoeft, Michael Rose\\
	School of Electrical Engineering and Computer Science\\
	Oregon State University}

% make the title area
\maketitle
\thispagestyle{empty} %removes page number


\begin{abstract}
A large project involves managing constantly changing repository, resolving merge conflicts, and trying to eliminate as many runtime errors as possible before they are introduced into the code base. Managers currently use purely text based diff tools to find any conflicts. Because these tools are text based and not semantic based, there is a higher probability that a runtime bug will be introduced into the code base.

Our project is a Roslyn Analyzer that helps identify non-semantic changes that can be ignored and semantic changes that may introduce potential runtime errors. Users will install our NuGet package in Visual Studio to receive warnings.

This project is designed to both reduce bug counts and save time for both the programmers and the project managers. By reducing potential runtime bugs, programmers will spend less time trying to replicate and debug runtime errors that can take large amounts of time to track down. The plugin should allow programmers and managers save time by producing code with fewer merge conflicts.
\end{abstract}
\newpage
\setcounter{page}{1}

\section{Introduction}
\subsection{Overview}
The purpose of this document is to demonstrate that SemDiff is currently at an alpha level release. This document starts with an introduction section that gives some background information and recaps our progress and goals. For each requirement we then have a section that restates the requirement and then describes progress toward that requirement. For every requirement, we will convey what work we have done, what work we have to do, show interesting code and images, and describe any problems that we have encountered. The document will then end with a short summary. Technical terms used throughout the document are explained in the Glossary at the end.

\subsection{Background}
Mass collaboration has a bulky overhead in a large software project. Git is one of the most popular version control systems and GitHub is the leading project hosting site for GitHub. The common workflow is that a developer will pick an issue (a bug or a new feature that needs to be worked on), make changes in a branch, then create a Pull Request. After the Pull Request is created, it is peer reviewed and then merged by management. Since repos contains hundreds of files and could have as many as 100 new pull requests a week it is impossible for every developer to be fully aware of all the pending changes. It is likely that at one point two developers will unintentionally make conflicting changes. Git uses a three-way merge to resolve most issues (this is referred to as text-based tool). This merge is generic and allows Git to use the same algorithm for all text files regardless of their content. However, the contents of files have lots of semantic information that is ignored.

There are two different conflicts that will be covered here, false-positives and false-negatives. A false-negative occurs when text-based tools find a conflict, however semantically there is no conflict. On the other hand, a false-positive occurs when text-based tools don’t find a conflict, but semantically there is a conflict.

An example of a false-positive, is the moved method conflict. Suppose that one developer, we will call him ‘A’, edits a method in a large file to fix a bug. He passes all tests so he creates a Pull Request with his changes. Before those changes are merged in, another developer, we will call him ‘B’, moves the same method that ‘A’ edited. ‘B’ might be moving the method because he was fixing a bug in another method and decided that moving the method made the code more readable. ‘B’ is unaware that ‘A’ edited the method because his environment provides no information about ‘B’s Pull Request. ‘B’s code passes all test, so he creates a Pull Request. Later their manager, we will call her ‘C’, verifies that the Pull Requests have been peer reviewed and attempts to merge them both in. One of the Pull Requests will merge correctly, however the other will fail because of the method conflict. This is a false-positive because semantically there is no conflict between ‘A’ and ‘B’s changes; the program will run the same wherever the method was moved or not. Because it failed to merge, now ‘C’ must take extra time to resolve the conflict and may require that ‘A’ and ‘B’ get involved to help figure out what happened.

False-negatives are much subtler and can introduce runtime bugs that can be very difficult to track down. These conflicts usually occur across files that have a semantic connection. For example, ‘R’ is implementing a new `DatabaseLogger`. The project already has a generic `Logger` that write logs to console shown in Figure 1. ‘R’ creates a `DatabaseLogger` class derived from `Logger` and overrides the `Log` method with logic to store logs in a database. ‘R’ does not override `LogAll` because he sees that it merely delegates to the `Log` method. However, ‘S’ notices that it is inefficient for the `Logger` in Figure 1 to be calling `Log` for every log instead of writing them all at once, so ‘S’ creates the logger shown in Figure 2. ‘S’ is unaware of ‘R’s work and ‘S’ is unaware of ‘R’s work. When ‘C’ goes to merge their Pull Requests, she finds that they merge with out errors (after all they didn’t even edit the same files). Even though they merge without error (and both ‘R’ and ‘S’s versions worked correctly) there is now a bug in the code. Whenever the `DatabaseLogger`’s `LogAll` method is called it will not log to the database, but to console. Because of the subtle nature of this bug it may be a long time before it is noticed and it may be difficult to debug.

The barrier to making tools that understand false-positives and false-negative is understanding the semantics of programs. With most languages this can be challenging because in order to get information about a program’s semantics it is necessary to build a parser, define an abstract syntax tree, and build all the logic for understanding what the syntax constructs do. All that work is redundant because the languages compiler already has to do all of that, moreover the compiler is the best source for semantic information because it implements the semantics. Sadly, most compilers are like black boxes, files go in and programs come out. Luckily the idea of the compiler as a service has become more popular. With a compiler as a service model, the compiler provides a rich set of APIs for inspecting and interpreting both the syntax trees and the semantic models of the code.

In the last few years Microsoft has built a new C\# and VB compiler that uses the compiler as a service model. This compiler is commonly known as ‘Roslyn.’ Roslyn provides (among other things) a `SyntaxTree` object that represents the abstract syntax tree of a file, a `SemanticModel` object that represents how a single `SyntaxTree` is connected to others, and a `DiagnosticAnalyzer` interface. The `SyntaxTree` and `SemanticModel` both have a rich interface for querying their data and getting the semantic information from the code. This rich set of APIs lowers the bar for developers that want to analyze the semantics of their code, this is why Roslyn provides the `DiagnosticAnalyzer` abstract class. It provides call backs that can be bound to in order to easily implement some custom logic that can report `Diagnostic` messages back to Roslyn. When this analyzer is installed it is integrated into the Roslyn pipeline and any `Diagnostic` messages are shown alongside compiler generated messages. These analyzers are commonly packaged as NuGet packages and installed to projects much like other software dependencies can be installed. Additionally, the diagnostics are tied to the project therefore only one developer needs to install an analyzer for all the projects developers to start receiving messages.

\subsection{Project Purpose and Goals}
The solution to this problem explained in the background is a semantic merge tool that uses semantics to merge files instead of a text-based approach. However, such tools are hard to write and hard to maintain. From a management point of view, the benefits of text-based merging outweigh the time spent resolving the merge conflicts by hand and detect false-positives by having comprehensive test suites. However, most projects do not have great test coverage and developers would rather write code than handle merge conflicts.

SemDiff hopes to find the middle ground between solving the problems of false-negatives and doing nothing to prevent them. SemDiff is a Roslyn analyzer that seeks to prevent false-negatives and false-positives before they happen by warning developers when we detect that their changes could cause a merge conflict. Both of the narratives in the background section could have been prevented by warning the developer that someone else was working on another in an area that could cause problems. If ‘A’ had known that ‘B’ had moved the method, he might have moved the method in his also. If ‘B’ had known that ‘A’ edited the method, he might not have moved it. Similarly, if ‘R’ had known about ‘S’s changes to the `Logger`, he would have implemented the `LogAll` method. Preventing these kinds of issues helps developers focus on code and not merge conflicts and helps prevent subtle bugs that are introduced by false-negatives.


\subsection{Overall Progress}
\subsubsection{Fall Term}
All our planning happened Fall Term. The team met with Phillip Carter almost every weekend to talk about the project. The team decided upon splitting up the project into 4 major parts, handling GitHub interaction, false-positive detection, false-negative detection, and error message generation. The team also refined a requirement document and a design document. The requirement document is echoed in this report structure because it is the main standard that has guided development.

\subsubsection{Winter Term (mid)}
Winter term is when the coding began. There is still a big portion of coding left, but one of the three major sections is more or less complete, GitHub interaction. GitHub interaction is closer to beta than alpha, where false-positive and false-negative pieces are still in alpha. The minor pieces of this project range from alpha to beta. The interaction between parts of the project are not complete, but missing elements have been stubbed out and the missing elements are well defined. The warnings system works but needs testing and it not actually connected to any logic for providing meaningful errors. SemDiff can currently create a NuGet package, the NuGet package installs and will pull down data from GitHub, but critical functionality is incomplete.

The team met with Phillip only once this term, on February 6th. This is by choice of both Phillip and the design team. There is much less to discuss unless the team runs into problems with Roslyn or has to communicate problems about the project. The meeting was more of a check-in than a discussion of what to do or where to go.

The team has met weekly on Mondays to do a code review of any pull requests that have been submitted as well as hash out any questions or concerns a member has moving forward. The team’s communication outside of the meeting time has also been good and all the members have been on the same page, leaving few miscommunications and problems.

\subsubsection{Winter Term (final)}


\section{Project Progress}
The following section details our progress on all of our requirements. For example, section 2.1 refers to requirement number 1 in our requirement document. The title of the section is a summary of the requirement; the actual requirement text is contained at the top of the section.

\subsection{Query HitHub for Pull Request}
“SemDiff will query the GitHub repo cloned in VS for pull request and the files changed”

\subsubsection{Progress}
SemDiff successfully queries GitHub and downloads all pull requests. The project keeps a list of pull requests and associated files. These pull requests are stored in a dictionary so that it is easy to determine if a pull request already exists locally. SemDiff has also implemented the ability to use OAuth to increase the number of API calls per hour from 60 to 5000. This is important because of the fact that each time SemDiff checks for pull requests, it has to check to see if there are any pull requests and then make another call for each pull request found.

The current system works for the purposes of the project, but because of the interaction with GitHub and the potential IO calls, the developers are going to optimize the code. To optimize the code, the project will check and see if the pull requests have been updated on GitHub before downloading the files. This will be done through the use of HTTP header files in conjunction with GitHub’s header responses. This will both reduce the number of API calls against an IP or authenticated user, as well as reduce the number of files downloaded each time GitHub is queried for pull requests. 

\subsubsection{Methodology}


\subsubsection{Future Work}
Before this requirement is complete we will need to handle the paginated format that GitHub uses. Currently if there are more than 20 pull requests open we cannot retrieve them all because they cannot be placed on the same page. The Implementation of this should be as simple as retrieving the url of the next page and (if it is not null) add the next page of pull requests to our list.

As of our alpha, we currently do not reuse data. So when we go and get data from GitHub we get all of it again. In the analyzer this could result in a complete copy of all the pull requests being downloaded every 5 minutes. This can be fixed by using `ETag`s provided by GitHub to determine if the resources we are requesting has changed. If the resource has changed, we will need to cache enough information to determine if the pull request has Changed, Added, Deleted and take appropriate action (including deleting old files).

\subsubsection{Problems}
This is the hardest part of our system to test, but also the most critical for us to test. We will need to build up more advanced test suites to effectively test how our software will handle pull requests changing.

Additionally, the GitHub API documentation is thorough, but there is no list of all the errors that the API can produce. This makes it hard for us to be sure that we are handling all the errors that could occur in the wild.

\subsection{False-Positive Detection}
“SemDiff will detect changes between two version of a file that will cause a text-based merge conflict but do not change the semantics of the code. This is defined as a false-positive. This will require at least partial completion of requirement 1, because we will need to know the format/state that we will receive files.
“Specifically: Another developer moves a function, Foo(), in Bar.cs without changing the semantics and creates a pull request, the current developer edits Foo() in its original location in Bar.cs. This creates a false-positive.”

\subsubsection{Progress}
False-positive detection is still incomplete. Currently, a 3-way diff has been created to help identify where potential locations of false-positives may reside, but the algorithm to detect if these differences are false positives has yet to be implemented. The algorithm has been tested (see Methodology), and there are only issues with whitespace.

\subsubsection{Methodology}


\subsubsection{Future Work}


\subsubsection{Problems}


\subsection{False-Negative Detection}
\subsubsection{Progress}


\subsubsection{Methodology}


\subsubsection{Future Work}


\subsection{Displaying False-Positive Warnings in Error List}
\subsubsection{Progress}


\subsubsection{Future Work}


\subsection{Displaying False-Negatives Warnings in Error List}
\subsubsection{Progress}


\subsubsection{Future Work}


\subsection{NuGet Package}
\subsubsection{Progress}


\subsubsection{Future Work}


\subsubsection{Problems}



\subsection{Performance}


\subsection{Informative Alerts}


\subsection{GitHub Project Hosting}
\subsubsection{Progress}


\subsubsection{Future Work}


\subsubsection{Problems}


\subsection{MIT Licensing}


\subsection{Documentation in Code}


\subsection{Development Technology}


\section{Conclusion}
From the above information it is clear that we have an alpha level product. There is lots of work to do but we have a good start to having a well refined product at expo.



\hfill mds
 
\hfill August 26, 2015

% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\begin{thebibliography}{1}

\bibitem{IEEEhowto:kopka}
H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.

\end{thebibliography}




\printglossaries

\end{document}
